{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Двухслойный перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы нужен файл clouds.data.h5. Если нет в папке - запустить 26_image_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Построить двухслойный перцептрон для типа облака Fish\n",
    "2. Оценить качество по коэффициенту сходства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 525\n",
    "image_y = 350\n",
    "\n",
    "\n",
    "def mask_rate(a, x, y):\n",
    "    b = a // 1400\n",
    "    return np.round(x*(b*x // 2100) + y*(a%1400) // 1400).astype(\"uint32\")\n",
    "\n",
    "def calc_mask(px, x=525, y=350):\n",
    "    p = np.array([int(n) for n in px.split(\" \")]).reshape(-1, 2)\n",
    "    mask = np.zeros(y*x, dtype=\"uint8\")\n",
    "    for i, m in p:\n",
    "        mask[mask_rate(i, x, y)-1:mask_rate(m + i, x, y)] = 1\n",
    "    return mask.reshape(y, x).transpose()\n",
    "\n",
    "def calc_dice(x):\n",
    "    dice = 0\n",
    "    px = x[\"EncodedPixels\"]\n",
    "    if px != px and x[\"target\"] == 0:\n",
    "        dice = 1\n",
    "    elif px == px and x[\"target\"] == 1:\n",
    "        mask = calc_mask(px).flatten()\n",
    "        target = np.ones(image_x*image_y, dtype=\"uint8\")\n",
    "        dice = 2*np.sum(target[mask==1]) / (np.sum(target) + np.sum(mask))\n",
    "    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузить данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3    4    5    6    7    8    9  ...  183745  183746  \\\n",
      "0   0   0    0    0    0    0    0    0    0    0  ...     102     113   \n",
      "1  72  43   32   39   49   69   71   47   25   22  ...      38      58   \n",
      "2  97  98  100  102  105  107  109  110  111  112  ...       0       0   \n",
      "3  88  87   90   94   94   89   87   87   82   82  ...     166     164   \n",
      "4  18  19   21   21   21   20   18   17   15   16  ...     125     137   \n",
      "\n",
      "   183747  183748  183749        Image  \\\n",
      "0     102      96     117  0011165.jpg   \n",
      "1      83     111     134  002be4f.jpg   \n",
      "2       0       0       0  0031ae9.jpg   \n",
      "3     109      70      72  0035239.jpg   \n",
      "4      93      60      49  003994e.jpg   \n",
      "\n",
      "                                                Fish  \\\n",
      "0  264918 937 266318 937 267718 937 269118 937 27...   \n",
      "1  233813 878 235213 878 236613 878 238010 881 23...   \n",
      "2  3510 690 4910 690 6310 690 7710 690 9110 690 1...   \n",
      "3                                                NaN   \n",
      "4  2367966 18 2367985 2 2367993 8 2368002 62 2369...   \n",
      "\n",
      "                                              Flower  \\\n",
      "0  1355565 1002 1356965 1002 1358365 1002 1359765...   \n",
      "1  1339279 519 1340679 519 1342079 519 1343479 51...   \n",
      "2  2047 703 3447 703 4847 703 6247 703 7647 703 9...   \n",
      "3  100812 462 102212 462 103612 462 105012 462 10...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                              Gravel  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  65400 380 66800 380 68200 380 69600 380 71000 ...   \n",
      "4  353317 416 354717 416 356117 416 357517 416 35...   \n",
      "\n",
      "                                               Sugar  \n",
      "0                                                NaN  \n",
      "1  67495 350 68895 350 70295 350 71695 350 73095 ...  \n",
      "2  658170 388 659570 388 660970 388 662370 388 66...  \n",
      "3                                                NaN  \n",
      "4  28011 489 29411 489 30811 489 32211 489 33611 ...  \n",
      "\n",
      "[5 rows x 183755 columns]\n"
     ]
    }
   ],
   "source": [
    "clouds = pd.read_hdf('../data/out/clouds.data.h5')\n",
    "print(clouds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оставить данные только по Fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds.drop(\n",
    "    labels=[\n",
    "        \"Image\",\n",
    "        \"Flower\",\n",
    "        \"Gravel\",\n",
    "        \"Sugar\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1    2    3    4    5    6    7    8   9  ...  183741  183742  \\\n",
      "3686   27   31   37   41   40   35   27   22   34  46  ...      53      63   \n",
      "1191   32   32   33   36   39   40   35   29   27  30  ...      61      85   \n",
      "1349   46   81   59   40   86   48    9  118   66   6  ...     180     193   \n",
      "4767   60   82   72  135  197  194  196  175  117  87  ...      59     133   \n",
      "2437  131  198  213  177  117   68   57   44   29  32  ...     176     151   \n",
      "\n",
      "      183743  183744  183745  183746  183747  183748  183749  \\\n",
      "3686      73      78      96      50      37      65      85   \n",
      "1191      40      25      26      26      27      27      27   \n",
      "1349     206     209     210     211     208     201     193   \n",
      "4767     181      75      77     116     122     117      84   \n",
      "2437      94      42      56      80      54      29      27   \n",
      "\n",
      "                                                   Fish  \n",
      "3686                                                NaN  \n",
      "1191                                                NaN  \n",
      "1349  3178 328 4578 328 5978 328 7378 328 8778 328 1...  \n",
      "4767  281775 329 283175 329 284575 329 285975 329 28...  \n",
      "2437  732824 430 734224 430 735624 430 737024 430 73...  \n",
      "\n",
      "[5 rows x 183751 columns]\n"
     ]
    }
   ],
   "source": [
    "clouds_train, clouds_test = train_test_split(clouds, test_size=0.2)\n",
    "del clouds\n",
    "print(clouds_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Двухслойный перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clouds_train[\"Fish\"].notnull().astype(\"int8\")\n",
    "x = pd.DataFrame(clouds_train).drop(labels=[\"Fish\"], axis=1)\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(31,),\n",
    "    max_iter=20,\n",
    "    activation=\"logistic\",\n",
    "    verbose=10,\n",
    "    random_state=1,\n",
    "    learning_rate_init=.02,\n",
    "    warm_start=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.73990315\n",
      "Iteration 2, loss = 0.68337871\n",
      "Iteration 3, loss = 0.68934231\n",
      "Iteration 4, loss = 0.69334777\n",
      "Iteration 5, loss = 0.69743538\n",
      "Iteration 6, loss = 0.69750033\n",
      "Iteration 7, loss = 0.69853543\n",
      "Iteration 8, loss = 0.70023779\n",
      "Iteration 9, loss = 0.70273096\n",
      "Iteration 10, loss = 0.70604421\n",
      "Iteration 11, loss = 0.70794807\n",
      "Iteration 12, loss = 0.70958805\n",
      "Iteration 13, loss = 0.70953672\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 14, loss = 0.71154238\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 15, loss = 0.71462263\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.71780139\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.71646315\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.71733332\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.71699925\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 20, loss = 0.71809489\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 21, loss = 0.72000904\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.71966185\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 23, loss = 0.72177135\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.72247196\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 25, loss = 0.72114428\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 0.72086886\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.72276327\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 28, loss = 0.72415912\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 0.72302232\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.72255854\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 31, loss = 0.72255924\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.72218402\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.72257574\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 34, loss = 0.72328907\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 35, loss = 0.72488258\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 0.72519199\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 37, loss = 0.72505186\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.72375537\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 39, loss = 0.72354283\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 40, loss = 0.72462271\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 41, loss = 0.72788179\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 42, loss = 0.72800732\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 43, loss = 0.72691386\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 44, loss = 0.72503571\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clouds_train) // 100):\n",
    "    model.partial_fit(x[i:i + 100], y[i:i + 100], classes=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказать значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          EncodedPixels  target\n",
      "2954  208010 312 209410 312 210810 312 212210 312 21...       0\n",
      "3585                                                NaN       0\n",
      "24    973171 62 973238 2 973244 2 973249 1 973265 8 ...       0\n",
      "5425                                                NaN       0\n",
      "2251                                                NaN       0\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({\"EncodedPixels\": clouds_test[\"Fish\"]})\n",
    "result[\"target\"] = model.predict(clouds_test.drop(labels=[\"Fish\"], axis=1))\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка по Дайсу\n",
    "Считаем, что область облака - это все изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP, Fish: 0.506\n"
     ]
    }
   ],
   "source": [
    "dice = result.apply(calc_dice, axis=1, result_type=\"expand\")\n",
    "print(f'MLP, Fish: {round(dice.mean(), 3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env_dsalgo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01c14519b4974e9683bf796b0f04b445c3210d47f2a006233f6cff14adf5564b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
