{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Иерархия логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построить 4 модели логистической регрессии:\n",
    "1. для 8, 6 и остальных классов\n",
    "2. для 2, 5 и остальных классов\n",
    "3. для 1, 7 и остальных классов\n",
    "4. для 3 и 4 -по убыванию частоты значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использовать перекрестную проверку при принятии решения об оптимальном наборе столбцов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверить предсказание через каппа-метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подключить библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from core.reduce_mem_usage import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/prudential/train.csv.gz\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Info_2_1\"] = data[\"Product_Info_2\"].str.slice(0, 1)\n",
    "data[\"Product_Info_2_2\"] = pd.to_numeric(data[\"Product_Info_2\"].str.slice(1, 2))\n",
    "data.drop(labels=[\"Product_Info_2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = [data]\n",
    "for un in data[\"Product_Info_2_1\"].unique():\n",
    "    s = pd.DataFrame()\n",
    "    s[\"Product_Info_2_1_\" + un] = data[\"Product_Info_2_1\"].isin([un]).astype(\"int8\")\n",
    "    list_df.append(s)\n",
    "data = pd.concat(list_df, axis=1)\n",
    "data.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Product_Info_1  Product_Info_3  Product_Info_4  Product_Info_5  \\\n",
      "0   2               1              10        0.076923               2   \n",
      "1   5               1              26        0.076923               2   \n",
      "2   6               1              26        0.076923               2   \n",
      "3   7               1              10        0.487179               2   \n",
      "4   8               1              26        0.230769               2   \n",
      "\n",
      "   Product_Info_6  Product_Info_7   Ins_Age        Ht        Wt  ...  \\\n",
      "0               1               1  0.641791  0.581818  0.148536  ...   \n",
      "1               3               1  0.059701  0.600000  0.131799  ...   \n",
      "2               3               1  0.029851  0.745455  0.288703  ...   \n",
      "3               3               1  0.164179  0.672727  0.205021  ...   \n",
      "4               3               1  0.417910  0.654545  0.234310  ...   \n",
      "\n",
      "   Medical_Keyword_46  Medical_Keyword_47  Medical_Keyword_48  Response  \\\n",
      "0                   0                   0                   0         8   \n",
      "1                   0                   0                   0         4   \n",
      "2                   0                   0                   0         8   \n",
      "3                   0                   0                   0         8   \n",
      "4                   0                   0                   0         8   \n",
      "\n",
      "   Product_Info_2_2  Product_Info_2_1_D  Product_Info_2_1_A  \\\n",
      "0                 3                   1                   0   \n",
      "1                 1                   0                   1   \n",
      "2                 1                   0                   0   \n",
      "3                 4                   1                   0   \n",
      "4                 2                   1                   0   \n",
      "\n",
      "   Product_Info_2_1_E  Product_Info_2_1_C  Product_Info_2_1_B  \n",
      "0                   0                   0                   0  \n",
      "1                   0                   0                   0  \n",
      "2                   1                   0                   0  \n",
      "3                   0                   0                   0  \n",
      "4                   0                   0                   0  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "data.fillna(value=-1, inplace=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оптимизировать память"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на - 49.49 Мб (минус 84.9%)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 133 entries, Id to Product_Info_2_1_B\n",
      "dtypes: float16(18), int16(1), int32(1), int8(113)\n",
      "memory usage: 8.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'InsuredInfo_1', 'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5', 'InsuredInfo_6', 'InsuredInfo_7', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1_D', 'Product_Info_2_1_A', 'Product_Info_2_1_E', 'Product_Info_2_1_C', 'Product_Info_2_1_B']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = [\n",
    "    \"Insurance_History\",\n",
    "    \"InsuredInfo\",\n",
    "    \"Medical_Keyword\",\n",
    "    \"Family_Hist\",\n",
    "    \"Medical_History\",\n",
    "    \"Product_Info\",\n",
    "]\n",
    "columns = [\n",
    "    \"Wt\",\n",
    "    \"Ht\",\n",
    "    \"Ins_Age\",\n",
    "    \"BMI\",\n",
    "]\n",
    "\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data, columns=columns)))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed[\"Response\"] = data[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "18391 -1.429833 -0.707398  1.424839 -1.434082  0.611857 -0.169414 -1.159587   \n",
      "32137 -1.124099 -1.687657 -0.921336 -0.431258  0.611857 -0.169414  0.862391   \n",
      "2700   0.662319  1.246540 -0.164865  0.030201  0.611857 -0.169414 -1.159587   \n",
      "21529 -1.453140 -1.937656  0.592844 -0.794832  0.611857 -0.169414 -1.159587   \n",
      "1914  -0.514003 -0.463978  0.743891 -0.333373 -1.634368 -0.169414  0.862391   \n",
      "\n",
      "              7         8         9  ...       116       117       118  \\\n",
      "18391  1.101046 -1.156735  1.130555  ... -0.083689  0.441621 -0.149284   \n",
      "32137 -1.013721  0.862242 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "2700   1.101046 -1.156735  1.130555  ... -0.083689 -2.264385 -0.149284   \n",
      "21529  1.101046 -1.156735  1.130555  ... -0.083689  0.441621 -0.149284   \n",
      "1914  -1.013721  0.862242 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "\n",
      "            119       120       121       122       123       124  Response  \n",
      "18391  2.134117 -1.331832  1.604350 -0.216001 -0.128866 -0.142142         2  \n",
      "32137  1.200458 -1.331832  1.604350 -0.216001 -0.128866 -0.142142         8  \n",
      "2700  -0.200031  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         6  \n",
      "21529  2.134117 -1.331832  1.604350 -0.216001 -0.128866 -0.142142         8  \n",
      "1914  -0.200031  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         2  \n",
      "\n",
      "[5 rows x 126 columns]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_transformed, test_size=0.2)\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающих данных пометим все классы, кроме 6 и 8, как 0 - и проведем обучение.\n",
    "Затем в оставшихся данных (в кот класс не равен 6 или 8) заменим все классы, кроме 7 и 1, на 0 - и снова проведем обучение и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимальный набор столбцов\n",
    "Для каждого уровня иерархии это будет свой набор столбцов в исходных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перекрестная проверка\n",
    "Разбиваем обущающую выборку на k частей. На каждой части обучаем модель. Затем проверяем 1-ю, 2-ю, 3-ю, 4-ю на 5-ой; 1-ю, 2-ю, 3-ю, 5-ю на 4-ой и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(df, columns):\n",
    "    x = pd.DataFrame(df, columns=columns)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(x, df[\"Response\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(df_train, columns):\n",
    "    model = regression_model(df_train, columns)\n",
    "    logr_grid = GridSearchCV(model, {}, cv=5, n_jobs=2, scoring=make_scorer(cohen_kappa_score))\n",
    "    x = pd.DataFrame(df_train, columns=columns)\n",
    "    logr_grid.fit(x, df_train[\"Response\"])\n",
    "    return logr_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_opt_columns(data_train):\n",
    "    kappa_score_opt = 0\n",
    "    columns_opt = []\n",
    "    for col in columns_transformed:\n",
    "        kappa_score = logistic_regression(data_train, [col])\n",
    "        if kappa_score > kappa_score_opt:\n",
    "            columns_opt = [col]\n",
    "            kappa_score_opt = kappa_score\n",
    "    for col in columns_transformed:\n",
    "        if col not in columns_opt:\n",
    "            columns_opt.append(col)\n",
    "            kappa_score = logistic_regression(data_train, columns_opt)\n",
    "            if kappa_score < kappa_score_opt:\n",
    "                columns_opt.pop()\n",
    "            else:\n",
    "                kappa_score_opt = kappa_score\n",
    "    return columns_opt, kappa_score_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем последовательно урезать набор данных при расчете более глубоких моделей: после получения разделения на 8 отсечем все данные со значение 8 и т.д.\n",
    "После каждого расчета модели будем вычислять значения в проверочной выборке. Проверочную выборку нулями заполнять не будем.\n",
    "Набор разделений 6/8, 2/5, 1/7, 3/4 дает наибольшую точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 0.4238871994942393 - [3, 0, 2, 4, 5, 6, 7, 8, 13, 15, 16, 17, 18, 21, 22, 23, 27, 29, 30, 33, 34, 37, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 65, 67, 68, 70, 71, 72, 75, 76, 77, 78, 79, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 106, 108, 109, 110, 111, 112, 113, 115, 116, 117, 120, 123]/n/n1 - 0.18115480282977808 - [21, 2, 3, 4, 5, 9, 13, 16, 17, 18, 19, 20, 22, 23, 25, 32, 33, 35, 36, 38, 39, 41, 46, 47, 48, 49, 50, 52, 53, 64, 66, 67, 68, 70, 72, 73, 75, 76, 80, 81, 86, 87, 89, 92, 94, 95, 96, 97, 99, 102, 106, 107, 113, 115, 119, 120, 121, 122, 123, 124]/n/n2 - 0.5419864599391615 - [75, 0, 1, 2, 4, 5, 6, 8, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 30, 32, 33, 38, 40, 43, 44, 45, 48, 50, 54, 56, 57, 58, 59, 60, 61, 62, 64, 66, 70, 71, 72, 73, 76, 77, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 106, 107, 109, 110, 111, 112, 115, 116, 118, 120]/n/n3 - 0.48838286102787176 - [3, 4, 5, 6, 7, 8, 11, 13, 16, 21, 24, 32, 36, 38, 39, 41, 42, 45, 48, 50, 52, 56, 67, 69, 74, 78, 80, 81, 82, 88, 98, 101, 105, 106, 109, 110, 111, 119]/n/n"
     ]
    }
   ],
   "source": [
    "responses = [\n",
    "    [6, 8],\n",
    "    [2, 5],\n",
    "    [1, 7],\n",
    "    [3, 4],\n",
    "]\n",
    "\n",
    "logr_models = [{} for _ in range(len(responses))]\n",
    "data_train_current = data_train.copy()\n",
    "\n",
    "for i, response in enumerate(responses):\n",
    "    m_train = data_train_current.copy()\n",
    "    if response != [3, 4]:\n",
    "        m_train[\"Response\"] = m_train[\"Response\"].apply(lambda x: 0 if x not in response else x)\n",
    "    columns_opt, kappa_score_opt = find_opt_columns(m_train)\n",
    "    logr_models[i] = {\n",
    "        \"model\": regression_model(m_train, columns_opt),\n",
    "        \"columns\": columns_opt,\n",
    "    }\n",
    "    if response != [3, 4]:\n",
    "        data_train_current = data_train_current[~data_train_current[\"Response\"].isin(response)]\n",
    "    \n",
    "    print(f\"{i} - {kappa_score_opt} - {columns_opt}\", end=\"/n/n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание данных и оценка модели\n",
    "Последовательно считаем предсказания для каждой классификации. После этого объединяем предсказание по иерархии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logr_hierarchy(x):\n",
    "    for response in range(len(responses)):\n",
    "        if x[\"target\" + str(response)] > 0:\n",
    "            x[\"target\"] = x[\"target\" + str(response)]\n",
    "            break;\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in range(len(responses)):\n",
    "    model = logr_models[response][\"model\"]\n",
    "    columns_opt = logr_models[response][\"columns\"]\n",
    "    x = pd.DataFrame(data_test, columns=columns_opt)\n",
    "    data_test[\"target\" + str(response)] = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "42084  1.367014  0.759700 -0.694766  1.144893  0.611857 -0.169414  0.862391   \n",
      "30541 -0.091734  1.003120 -0.164865 -0.658991  0.611857 -0.169414 -1.159587   \n",
      "19980  2.773664 -0.707398 -1.526761  4.325164  0.611857 -0.169414 -1.159587   \n",
      "2819  -1.242006 -1.444237  0.062943 -0.764867  0.611857 -0.169414  0.862391   \n",
      "13532  0.544412  0.516280  0.289513  0.361812  0.611857 -0.169414  0.862391   \n",
      "\n",
      "              7         8         9  ...       121       122       123  \\\n",
      "42084 -1.013721  0.867624 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "30541  1.101046 -1.156735  1.130555  ... -0.623305 -0.216001 -0.128866   \n",
      "19980  1.101046 -1.156735  1.130555  ... -0.623305 -0.216001 -0.128866   \n",
      "2819   0.043662  0.864934 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "13532 -1.013721  0.864260 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "\n",
      "            124  Response  target0  target1  target2  target3  target  \n",
      "42084 -0.142142       6.0      0.0      0.0      7.0      3.0     7.0  \n",
      "30541 -0.142142       6.0      0.0      0.0      7.0      4.0     7.0  \n",
      "19980 -0.142142       1.0      0.0      5.0      7.0      3.0     5.0  \n",
      "2819  -0.142142       8.0      8.0      0.0      7.0      4.0     8.0  \n",
      "13532 -0.142142       2.0      0.0      0.0      7.0      3.0     7.0  \n",
      "\n",
      "[5 rows x 131 columns]\n"
     ]
    }
   ],
   "source": [
    "data_test = data_test.apply(logr_hierarchy, axis=1, result_type=\"expand\")\n",
    "print(data_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4983902944210179, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'{cohen_kappa_score(data_test[\"target\"], data_test[\"Response\"], weights=\"quadratic\"), 3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 467  347   27   26  193  470  149  141]\n",
      " [ 173  230    4    1   87   75   10    4]\n",
      " [  41   49   76   33   86  161   22    4]\n",
      " [  57   54   60  147   23  274   50   64]\n",
      " [  68  132   12    0  210   58   22    9]\n",
      " [  18   25   13   21   11  138   23   38]\n",
      " [ 232  274   13   13  342  739  827  492]\n",
      " [ 190  163   10   45  141  353  507 3133]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(data_test[\"target\"], data_test[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env_dsalgo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01c14519b4974e9683bf796b0f04b445c3210d47f2a006233f6cff14adf5564b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
